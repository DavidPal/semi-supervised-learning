\section{All functions}
\label{section:all-functions}

Let $\X$ be some finite domain.
A learner $A$ is said to be \emph{consistent} if, given some labeled sample $T = (x_1,y_1), \dots,(x_m,y_m) \subseteq (\X \times \{0,1\})^m$, $A(T) \in \{0,1\}^\X$ maps $x_i$ to $y_i$ for each $i=1,\dots, m$.
In this section we show that consistent distribution independent learners are almost as powerful for $C = \{0,1\}^\X$ as any distribution independent learner.

Before we state and prove the result formally, we introduce some further notations.
Given some distribution $P$ over $\X$,
let $m_B(P,\epsilon,\delta)$ denote the smallest number $m$ with $\inf_{c \in C} \Pr_{T_c}[d_P(B(T_c),c) \geq \epsilon] \leq \delta$, where, for $c \in C$, $T_c(m) = T_c = \{(X_1,c(X_1)), \dots, (X_m,c(X_m))\}$ with $X_1, \dots, X_m$ being i.i.d. samples from $P$, as described in Section~\ref{section:preliminaries}.


\begin{theorem}
Let $\X$ be some finite domain, $C = \{0,1\}^\X$ and $A$ be any consistent learner for $C$.
Then, for any distribution $P$ over $\X$ and any (possibly distribution dependent) learner $B$ for $C$,
\(
m_A(P,2\epsilon,2\delta) \leq m_B(P,\epsilon,\delta)
\).
\end{theorem}
 
\begin{proof}
Fix some integer $m \geq 0$ and some distribution $P$ over $\X$.

First of all note that, 
for any $c \in C$ and any $T_c$,
\begin{equation}
\label{eq: relate dP(A,c) to z(Tc)}
	d_P(A(T_{c}),c) \leq z(T_c)
	\;.
\end{equation}

Let now $\tilde{T} = (X_i,Y(X_i))_{i=1}^m$ be a random sample generated by choosing first $(X_1, \dots, X_m)$ uniformly at random from $\X^m$ and then choosing $Y$ uniformly at random from $\{0,1\}^{\{X_1, \dots, X_m\}}$.
Additionally, choose $c'$ uniformly at random from $\{0,1\}^{\X \setminus \{X_1, \dots, X_m\}}$, and let $c' \circ \tilde{T}$ denote the function that maps $X_i$ to $Y(X_i)$ for $i=1,\dots,n$, and $x \in (\X \setminus \{X_1, \dots, X_n\})$ to $c'(x)$.
Finally, choose $\tilde{c}$ uniformly at random from $C$.
Then,
\begin{align}
	&
	\sup_{c \in C}\Pr_{T_c}[d_P(B(T_c),c) \geq \epsilon] 
	\notag\\
	&=
	\sup_{c \in C}\Exp_{T_c}\left[ 
		\mathbf{1}_{\left\{ d_P\left(B\left( T_c\right),c \right) \geq \epsilon \right\}}
	\right] 
	\notag\\
	&\geq \Exp_{\tilde{c}}\left[
		\Exp_{T_{\tilde{c}}}\left[ 
			\mathbf{1}_{\left\{d_P\left(B\left( \tilde{T}\right),\tilde{c} \right) \geq \epsilon \right\}}
		\right]
	\right]
	\notag\\
	&= \Exp_{\tilde{T}} \left[
		\Exp_{c'} \left[
			\mathbf{1}_{\left\{d_P\left(B\left( \tilde{T}\right),c'\circ \tilde{T} \right) \geq \epsilon \right\}}
		\right] 
	\right]
	\notag\\
	&\geq \Exp_{\tilde{T}} \left[
		\frac{1}{2} \mathbf 1_{\left\{ \frac{1}{2}z\left( \tilde{T} \right) \geq \epsilon \right\}}
	\right]
	\label{eq: switch to 2epsilon}
	\\
	&= \frac{1}{2}\sup_{c \in C}\Exp_{T_c} \left[
		\mathbf 1_{\left\{ z\left( T_c \right) \geq 2\epsilon \right\}}
	\right]
	\label{eq: switch back to sup}
	\\
	&= \frac{1}{2}\sup_{c \in C}\Pr_{T_c} \left[
		z\left( T_c \right) \geq 2\epsilon
	\right]
	\notag
	\\
	&\geq \frac{1}{2}\sup_{c \in C}\Pr_{T_c} \left[
		d_P(A(T_c) , c) \geq 2\epsilon
	\right]
	\label{eq: use the relation of d(A(T),c) and z(T)}
	 \;,
\end{align}
where
\begin{itemize}
\item 
\eqref{eq: switch to 2epsilon} follows
because, for any $c'$, denoting the conjugate of $c'$ by $\overline{c'}$, we have
\(
  d_P\left(f,c'+{T} \right) 
  +
  d_P\left(f,\overline{c'}+{T} \right)
  =
  z\left({T}\right)
\)
for any $f \in \{0,1\}^\X$ and sample $T$, and thus $(1/2)z(T) \geq \epsilon$ holds only when for any $c'$ at least one of $d_P\left(f,c'+{T} \right) \geq \epsilon$ and $d_P\left(f,\overline{c'}+{T} \right) \geq \epsilon$ also holds,
\item
\eqref{eq: switch back to sup} follows because $z(T)$ does not depend on the labels in $T$,
\item
and \eqref{eq: use the relation of d(A(T),c) and z(T)} follows by \eqref{eq: relate dP(A,c) to z(Tc)}.
\end{itemize}
The statement of the theorem follows.
\end{proof}

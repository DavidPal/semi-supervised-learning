% The \icmltitle you define below is probably too long as a header.
% Therefore, a short form for the running title is supplied here:
\icmltitlerunning{The information-theoretic value of unlabeled data in semi-supervised learning}

\twocolumn[
\icmltitle{The information-theoretic value of unlabeled data in semi-supervised learning}

\begin{icmlauthorlist}
\icmlauthor{Alexander Golovnev}{harvard}
\icmlauthor{D\'avid P\'al}{yahoo}
\icmlauthor{Bal\'azs Sz\"or\'enyi}{yahoo}
\end{icmlauthorlist}

\icmlaffiliation{harvard}{Harvard University, Cambridge, MA, USA}
\icmlaffiliation{yahoo}{Yahoo Research, New York, NY, USA}

\icmlcorrespondingauthor{D\'avid P\'al}{davidko.pal@gmail.com}

\icmlkeywords{semi-supervised learning, PAC learning, sample complexity, unlabeled data}

\vskip 0.3in
]

\printAffiliationsAndNotice{}

\begin{abstract}
We quantify the separation between the numbers of labeled examples required to
learn in two settings: Settings \emph{with} and \emph{without} the knowledge of
the distribution of the unlabeled data. More specifically, we prove a separation
by $\Theta(\log n)$ multiplicative factor for the class of projections over
the Boolean hypercube of dimension $n$.

Learning with the knowledge of the distribution (a.k.a. \emph{fixed-distribution
learning}) can be viewed as an idealized scenario of semi-supervised learning
where the number of unlabeled data points is so great that the unlabeled
distribution is known exactly. For this reason, we call the separation the
\emph{value of unlabeled data}.
\end{abstract}
